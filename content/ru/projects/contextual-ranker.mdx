---
title: "Контекстный ранкер для рекомендаций маркетплейса"
summary: "Построил быстрый candidate→rank пайплайн с надежной оценкой и guardrails для высоконагруженного маркетплейса."
tags: ["RecSys", "MLOps"]
stack: ["PyTorch", "Faiss", "Feature Store", "Kafka", "Kubernetes", "Postgres"]
metrics: ["CTR +6.4%", "P95 задержка 55мс", "Стоимость −18% (GPU→CPU)"]
role: "Ведущий ML инженер"
year: 2025
links:
  github: "https://github.com/your-handle/contextual-ranker"
  demo: "https://example.com/demo"
  article: "https://example.com/writeup"
featured: true
slug: "contextual-ranker"
---

## Проблема / контекст

Главной странице маркетплейса требовались рекомендации, которые были бы **персонализированными**, **свежими** и **быстрыми**. Предыдущая система была одноэтапной и проваливалась в онлайне из-за дрейфа признаков.

Ограничения:

- **P95 задержка:** &lt; 60мс на запрос (ранжирование)
- **Трафик:** GPU-инференс слишком дорогой
- **Наблюдаемость:** нужны срезы по новым пользователям/товарам и long-tail

## Подход / пайплайн

Двухэтапная архитектура с четкими контрактами данных:

```text
[Events] -> [Feature Store] -> [Candidate Gen (Two-Tower)] -> [ANN Search]
                                          |                   |
                                          v                   v
                                 [Re-ranker (LightGBM)] -> [Business Rules] -> [Serve]
```

Ключевые идеи:

- **Генерация кандидатов** нацелена на recall и свежесть (быстрый ANN).
- **Ранкер** оптимизирует калиброванный CTR с жесткой проверкой паритета признаков.
- **Оценка** учитывает согласованность офлайн/онлайн через контрфактуальные проверки.

## Данные

- Имплицитные сигналы (клики, сохранения) с дебайсингом.
- Фичи популярности с затуханием по времени для новых товаров.
- Строгие контракты: у каждой фичи был владелец, тесты и стратегия бэкфилла.

> Примечание: детали данных намеренно обобщены.

## Результаты

- **CTR +6.4%** на главном экране (A/B, 2 недели)
- **P95 задержка 55мс** end-to-end для ранжирования
- **Стоимость −18%** за счет CPU-инференса и батчинга

## Что бы сделал дальше

- Добавил бы exploration-политику, чтобы снизить петли обратной связи.
- Улучшил бы оценки неопределенности для cold-start пользователей.
